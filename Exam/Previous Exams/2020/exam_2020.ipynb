{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following **linear equation:**\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\epsilon_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume you have access to data of the **independent variables** ($x_{1,i}$, $x_{2,i}$) and the **dependent variable** ($y_i$) for $N$ individuals, where $i$ indexes individuals. The variable $\\epsilon_i$ is a mean-zero **stochastic shock**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the **data generating process** is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGP(N):\n",
    "    \n",
    "    # a. independent variables\n",
    "    x1 = np.random.normal(0,1,size=N)\n",
    "    x2 = np.random.normal(0,1,size=N)\n",
    "    \n",
    "    # b. errors\n",
    "    eps = np.random.normal(0,1,size=N)\n",
    "    \n",
    "    extreme = np.random.uniform(0,1,size=N)\n",
    "    eps[extreme < 0.05] += np.random.normal(-5,1,size=N)[extreme < 0.05]\n",
    "    eps[extreme > 0.95] += np.random.normal(5,1,size=N)[extreme > 0.95]\n",
    "    \n",
    "    # c. dependent variable\n",
    "    y = 0.1 + 0.3*x1 + 0.5*x2 + eps\n",
    "    \n",
    "    return x1, x2, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data you have access to is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "x1,x2,y = DGP(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Estimate the vector of coefficients $\\mathbf{\\beta} = (\\beta_0,\\beta_1,\\beta_2)$ using **ordinary least squares (OLS)** implemented with **matrix algebra** by\n",
    "\n",
    "$$ \\hat{\\mathbf{\\beta}} = (\\mathbf{X}^{\\prime}\\mathbf{X})^{-1}\\mathbf{X}^{\\prime}\\mathbf{y} $$\n",
    "\n",
    "where $\\mathbf{X}^{\\prime}$ is the transpose of $\\mathbf{X}$ and\n",
    "\n",
    "$$\\mathbf{y} = \n",
    "\\pmatrix{ y_1 \\cr y_2 \\cr  \\vdots \\cr y_N \n",
    "}\n",
    ", \\quad \\mathbf{X} = \\pmatrix{\n",
    "1 & x_{1,1} & x_{2,1} \\cr \n",
    "1 & x_{1,2} & x_{2,2} \\cr \n",
    "\\vdots & \\vdots \\cr \n",
    "1 & x_{1,N} & x_{2,N} \n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Construct a 3D plot, where the data is plotted as scattered points, and the prediction of the model is given by the plane\n",
    "\n",
    "$$\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1,i} + \\hat{\\beta}_2 x_{2,i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Esimtate the vector of coefficients $\\mathbf{\\beta} = (\\beta_0,\\beta_1,\\beta_2)$ using a **numerical solver** to solve the ordinary least square problem, shown below, directly. Compare your results with the matrix algebra results.\n",
    "\n",
    "$$ \\min_{\\mathbf{\\beta}} \\sum^N_{i=1} (y_i - (\\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i}) )^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Estimate the vector of coefficients $\\mathbf{\\beta} = (\\beta_0,\\beta_1,\\beta_2)$ using **least absolute deviations (LAD)** using a numerical solver to solve the following problem directly: \n",
    "\n",
    "$$  \\min_{\\beta} \\sum^N_{i=1} |y_i - (\\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i}) | $$\n",
    "\n",
    "where $|z|$ is the absolute value of $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Set $N = 50$. Repeat the estimation using the **OLS** and **LAD** methods $K=5000$ times, drawing a new random sample from the data generating process each time. Compare the estimates from each method using histograms. Which method do you prefer? Explain your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durable purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a **household** living in two periods.\n",
    "\n",
    "In the **second period** it gets utility from **non-durable consumption**, $c$, and **durable consumption**, $d+\\chi x$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{2}(m_{2},d)&= \\max_{c}\\frac{(c^{\\alpha}(d+\\chi x)^{1-\\alpha})^{1-\\rho}}{1-\\rho}\\\\\n",
    "\\text{s.t.} \\\\\n",
    "x &= m_{2}-c \\\\\n",
    "c &\\in [0,m_{2}]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $m_2$ is cash-on-hand in the beginning of period 2\n",
    "* $c$ is non-durable consumption\n",
    "* $d$ is pre-commited durable consumption\n",
    "* $x = m_2 - c$ is extra durable consumption\n",
    "* $\\rho > 1$ is the risk aversion coefficient\n",
    "* $\\alpha \\in (0,1)$ is the utility weight on non-durable consumption\n",
    "* $\\chi \\in (0,1)$ implies that extra durable consumption is *less* valuable than pre-comitted durable consumption\n",
    "* the second constraint ensures the household *cannot* die in debt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **value function** $v_2(m_2,d)$ measures the household's value of having $m_2$ at the beginning of period 2 with precomitted durable consumption of $d$. The optimal choice of non-durable consumption is denoted $c^{\\ast}(m_2,d)$. The optimal extra durable consumption function is $x^{\\ast}(m_2,d) = m_2-c^{\\ast}(m_2,d)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the so-called **end-of-period 1 value function** as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w(a,d)&\\equiv\\beta\\mathbb{E}_{1}\\left[v_2(m_2,d)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "m_2&= (1+r)a+y \\\\\n",
    "y &= \\begin{cases}\n",
    "1-\\Delta & \\text{with prob. }\\frac{1}{3}\\\\\n",
    "1 & \\text{with prob. }\\frac{1}{3}\\\\\n",
    "1+\\Delta & \\text{with prob. }\\frac{1}{3}\n",
    "\\end{cases}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "* $a$ is assets at the end of period 1\n",
    "* $\\beta > 0$ is the discount factor\n",
    "* $\\mathbb{E}_1$ is the expectation operator conditional on information in period 1\n",
    "* $y$ is income in period 2\n",
    "* $\\Delta \\in (0,1)$ is the level of income risk (mean-preserving)\n",
    "* $r$ is the return on savings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **first period**, the household chooses it's pre-comitted level of durable consumption for the next-period,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{1}(m_{1})&=\\max_{d} w(a,d)\\\\&\\text{s.t.}&\\\\\n",
    "a&= m_{1}-d \\\\\n",
    "d&\\in [0,m_{1}]\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $m_1$ is cash-on-hand in period 1. The second constraint ensures the household *cannot* borrow. The **value function** $v_1(m_1)$ measures the household's value of having $m_1$ at the beginning of period 1. The optimal choice of pre-committed durable consumption is denoted $d^{\\ast}(m_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **parameters** and **grids** for $m_1$, $m_2$ and $d$ should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. parameters\n",
    "rho = 2\n",
    "alpha = 0.8\n",
    "beta = 0.96\n",
    "r = 0.04\n",
    "Delta = 0.25\n",
    "\n",
    "# b. grids\n",
    "m1_vec = np.linspace(1e-8,10,100)\n",
    "m2_vec = np.linspace(1e-8,10,100)\n",
    "d_vec = np.linspace(1e-8,5,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Find and plot the functions $v_{2}(m_{2},d)$, $c^{\\ast}(m_2,d)$, and $x^{\\ast}(m_2,d)$. Comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Find and plot the functions $v_{1}(m_{1})$ and $d^{\\ast}(m_1)$. Comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** For interpolation of $v_2(m_2,d)$ consider using `interpolate.RegularGridInterpolator([GRID-VECTOR1,GRID-VECTOR2],VALUE-MATRIX,bounds_error=False,fill_value=None)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, consider an **extension** of the model, where there is also a **period 0**. In this period, the household makes a choice whether to stick with the level of durables it has, $z = 0$, or adjust its stock of durables, $z = 1$. If adjusting, the household loses a part of the value of its durable stock; more specificaly it incurs a proportional loss of $\\Lambda \\in (0,1)$.\n",
    "\n",
    "Mathematically, the **household problem in period 0** is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{0}(m_{0},d_{0}) &= \\max_{z\\in\\{0,1\\}} \\begin{cases}\n",
    "w(m_{0},d_{0}) & \\text{if } z = 0\\\\\n",
    "v_1(m_0+(1-\\Lambda) d_{0}) & \\text{if } z = 1\\\\\n",
    "\\end{cases}\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **parameters** and **grids** for $m_0$ and $d_0$ should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda = 0.2\n",
    "m0_vec = np.linspace(1e-8,6,100)\n",
    "d0_vec = np.linspace(1e-8,3,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** For which values of $m_0$ and  $d_0$ is the optimal choice not to adjust, i.e. $z = 0$? Show this in a plot. Give an interpretion of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\boldsymbol{x} = \\left[\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2\\\\\n",
    "\\end{array}\\right]$ be a two-dimensional vector. Consider the following algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm:** `gradient_descent()`\n",
    "\n",
    "**Goal:** Minimize the function $f(\\boldsymbol{x})$.\n",
    "\n",
    "1. Choose a tolerance $\\epsilon>0$, a scale factor $ \\Theta > 0$, and a small number $\\Delta > 0$\n",
    "2. Guess on $\\boldsymbol{x}_0$ and set $n=1$\n",
    "3. Compute a numerical approximation of the jacobian for $f$ by\n",
    "\n",
    "    $$\n",
    "    \\nabla f(\\boldsymbol{x}_{n-1}) \\approx \\frac{1}{\\Delta}\\left[\\begin{array}{c}\n",
    "    f\\left(\\boldsymbol{x}_{n-1}+\\left[\\begin{array}{c}\n",
    "    \\Delta\\\\\n",
    "    0\n",
    "    \\end{array}\\right]\\right)-f(\\boldsymbol{x}_{n-1})\\\\\n",
    "    f\\left(\\boldsymbol{x}_{n-1}+\\left[\\begin{array}{c}\n",
    "    0\\\\\n",
    "    \\Delta\n",
    "    \\end{array}\\right]\\right)-f(\\boldsymbol{x}_{n-1})\n",
    "    \\end{array}\\right]\n",
    "    $$\n",
    "\n",
    "4. Stop if the maximum element in $|\\nabla f(\\boldsymbol{x}_{n-1})|$ is less than $\\epsilon$\n",
    "5. Set $\\theta = \\Theta$ \n",
    "6. Compute $f^{\\theta}_{n} = f(\\boldsymbol{x}_{n-1} - \\theta \\nabla f(\\boldsymbol{x}_{n-1}))$\n",
    "7. If $f^{\\theta}_{n} < f(\\boldsymbol{x}_{n-1})$ continue to step 9\n",
    "8. Set $\\theta = \\frac{\\theta}{2}$ and return to step 6     \n",
    "9. Set $x_{n} = x_{n-1} - \\theta \\nabla f(\\boldsymbol{x}_{n-1})$\n",
    "10. Set $n = n + 1$ and return to step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Implement the algorithm above such that the code below can run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f,x0,epsilon=1e-6,Theta=0.1,Delta=1e-8,max_iter=10_000):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test case:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not implemented yet\n"
     ]
    }
   ],
   "source": [
    "def rosen(x):\n",
    "    return (1.0-x[0])**2+2*(x[1]-x[0]**2)**2\n",
    "\n",
    "x0 = np.array([1.1,1.1])\n",
    "try:\n",
    "    x,it = gradient_descent(rosen,x0)\n",
    "    print(f'minimum found at ({x[0]:.4f},{x[1]:.4f}) after {it} iterations')\n",
    "    assert np.allclose(x,[1,1])\n",
    "except:\n",
    "    print('not implemented yet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
